{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvtRHFXTXCh7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "# ---- 1. DataSplitter Class ----\n",
        "class DataSplitter:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.train_data = None\n",
        "        self.val_data = None\n",
        "        self.test_data = None\n",
        "\n",
        "    def split(self, test_size=0.2, val_size=0.5, random_state=42):\n",
        "        train_val, test = train_test_split(self.data, test_size=test_size, random_state=random_state)\n",
        "        train, val = train_test_split(train_val, test_size=val_size, random_state=random_state)\n",
        "        self.train_data = train.reset_index(drop=True)\n",
        "        self.val_data = val.reset_index(drop=True)\n",
        "        self.test_data = test.reset_index(drop=True)\n",
        "        return self.train_data, self.val_data, self.test_data\n",
        "\n",
        "# ---- 2. Utility to Create History Matrix ----\n",
        "def generate_history_matrix(data, row='user', value_field='rate', max_history_len=None, user_num=None, item_num=None):\n",
        "    inter_feat = data.sample(frac=1).reset_index(drop=True)\n",
        "    users, items = inter_feat['uid'].to_numpy(), inter_feat['vid'].to_numpy()\n",
        "    values = inter_feat[value_field].to_numpy() if value_field else np.ones(len(inter_feat))\n",
        "\n",
        "    if row == 'user':\n",
        "        row_ids, col_ids = users, items\n",
        "        row_num = user_num\n",
        "    else:\n",
        "        row_ids, col_ids = items, users\n",
        "        row_num = item_num\n",
        "\n",
        "    history_len = np.zeros(row_num, dtype=np.int64)\n",
        "    for r in row_ids:\n",
        "        history_len[r] += 1\n",
        "\n",
        "    max_len = np.max(history_len) if max_history_len is None else min(max_history_len, np.max(history_len))\n",
        "    history_matrix = np.zeros((row_num, max_len), dtype=np.int64)\n",
        "    history_value = np.zeros((row_num, max_len))\n",
        "    history_len[:] = 0\n",
        "\n",
        "    for r, c, v in zip(row_ids, col_ids, values):\n",
        "        if history_len[r] < max_len:\n",
        "            history_matrix[r, history_len[r]] = c\n",
        "            history_value[r, history_len[r]] = v\n",
        "            history_len[r] += 1\n",
        "\n",
        "    return (\n",
        "        torch.LongTensor(history_matrix),\n",
        "        torch.FloatTensor(history_value),\n",
        "        torch.LongTensor(history_len)\n",
        "    )\n",
        "\n",
        "# ---- 3. Sparse Matrix Generator ----\n",
        "def create_sparse_interaction_matrix(data, user_num, item_num, value_field='rate'):\n",
        "    users = data['uid'].to_numpy()\n",
        "    items = data['vid'].to_numpy()\n",
        "    values = data[value_field].to_numpy() if value_field else np.ones(len(data))\n",
        "    sparse_mat = coo_matrix((values, (users, items)), shape=(user_num, item_num))\n",
        "    return sparse_mat\n",
        "\n",
        "# ---- 4. Simple Feedforward Model ----\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# ---- 5. Training Function ----\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "# ---- 6. Evaluation Function ----\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "    return val_loss / len(val_loader)\n",
        "\n",
        "# ---- 7. Main Code ----\n",
        "if __name__ == \"__main__\":\n",
        "    logging.getLogger().setLevel(logging.WARNING)\n",
        "\n",
        "    # Load dataset\n",
        "    data = pd.read_csv(\"/u.data\", sep='\\t', header=None)\n",
        "    data.columns = ['uid', 'vid', 'rate', 'time']\n",
        "    data['uid'] -= 1\n",
        "    data['vid'] -= 1\n",
        "    user_num = data['uid'].max() + 1\n",
        "    item_num = data['vid'].max() + 1\n",
        "\n",
        "    # Split the dataset\n",
        "    splitter = DataSplitter(data)\n",
        "    train_data, val_data, test_data = splitter.split()\n",
        "\n",
        "    # Generate history matrices\n",
        "    history_matrix_train, history_value_train, _ = generate_history_matrix(train_data, row='user', value_field='rate', user_num=user_num, item_num=item_num)\n",
        "    history_matrix_val, history_value_val, _ = generate_history_matrix(val_data, row='user', value_field='rate', user_num=user_num, item_num=item_num)\n",
        "    history_matrix_test, history_value_test, _ = generate_history_matrix(test_data, row='user', value_field='rate', user_num=user_num, item_num=item_num)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(list(zip(history_matrix_train, history_value_train)), batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(list(zip(history_matrix_val, history_value_val)), batch_size=32, shuffle=False)\n",
        "    test_loader = DataLoader(list(zip(history_matrix_test, history_value_test)), batch_size=32, shuffle=False)\n",
        "\n",
        "    # Model, Loss, Optimizer Setup\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    input_size = history_matrix_train.shape[1]\n",
        "    model = SimpleModel(input_size=input_size, output_size=1).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Final Test Evaluation\n",
        "    test_loss = evaluate(model, test_loader, criterion, device)\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n"
      ]
    }
  ]
}